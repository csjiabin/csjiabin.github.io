---
title: Nginx负载均衡配置与负载策略
categories: nginx
date: 2019-02-15 15:43:27
subtitle: null
tags: 
  - nginx
  - 负载均衡
permalink: /pages/5b0d62/
author: 
  name: csjiabin
  link: https://github.com/csjiabin
---

## 原理

负载均衡的目的是为了解决单个节点压力过大，造成 Web 服务响应过慢，严重的情况下导致服务瘫痪，无法正常提供服务。

## 应用场景

春节期间在 12306 网站上买过火车票的朋友应该深有体会，有时查询一张火车票都会很慢，甚至整个网页都卡住不动了。通常一个访问量非常大的 Web 网站（比如：淘宝、京东、12306 等），由于一个 Web 服务同时能处理的用户并发请求的数量有限，同时还有机器故障的情况，所以一个 Web 站点通常会在 N 台机器上各部署一套同样的程序。当某一个服务挂掉的时候，还有第二个、第三个、第 N 个服务。。。继续为用户提供服务，给用户的感觉，你的服务还在正常的运行！在这些提供同样服务的机器当中，在硬件配置方面也各不一样，这样就会存在部份机器性能非常好，能快速计算并响应用户的请求，另外一部份机器可能配置差点，响应用户的请求的时间会长一些。

这就需要我们思考一个问题？如果有一个服务正在同时处理 1000 个用户的请求，这个服务的上限可能最多能同时处理 1000 个用户的请求，这时它已经很忙了，如果此时又有一个新请求过来，我们仍然把这个请求分配给这台机器，这时候这个请求就只能在干等着，等这个服务处理完那些请求后，再继续处理它。这样在浏览器中的反应就像 12306 我们在春节买票一样，卡在那不动了，让用户眼巴巴的干着急。而能提供同样服务的其它机器，这时确很空闲。这样不仅是对服务器资源的浪费，也充分发挥不出弄多台服务器装同一个服务的最高价值。
我们通常称对某一台机器的访问量称为负载量，如何将一个用户的请求，合理的分配到一台能快速响应用户请求的服务器上，我们就需要用到一些负载策略。也就体现出了文章主题的用意了：
负载均衡，将用户的所有 HTTP 请求均衡的分配到每一台机器上，充分发挥所有机器的性能，提高服务的质量和用户体验。
负载均衡可以通过负载均衡网络硬件设备和 Web 服务器软件来实现，前者设备成本较高，小公司通常负担不起，所以后者一般是我们的首选。
实现负载均衡常用的 Web 服务器软件有 Nginx、HAProxy、LVS、Apache，本文主要介绍 Nginx 的负载均衡策略。

## 一、内置负载策略

Nginx 负载均衡是通过 upstream 模块来实现的，内置实现了三种负载策略，配置还是比较简单的。

- 轮循（默认）
  Nginx 根据请求次数，将每个请求均匀分配到每台服务器
- 最少连接
  将请求分配给连接数最少的服务器。Nginx 会统计哪些服务器的连接数最少。
- IP Hash
  绑定处理请求的服务器。第一次请求时，根据该客户端的 IP 算出一个 HASH 值，将请求分配到集群中的某一台服务器上。后面该客户端的所有请求，都将通过 HASH 算法，找到之前处理这台客户端请求的服务器，然后将请求交给它来处理。

**轮循**

```nginx
http {

    # ... 省略其它配置

    upstream tomcats {
        server 192.168.0.100:8080;
        server 192.168.0.101:8080;
        server example.com:8080;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://tomcats;
        }
    }

    # ... 省略其它配置
}
```

- **proxy_pass http://tomcats：** 表示将所有请求转发到 tomcats 服务器组中配置的某一台服务器上。
- **upstream 模块：** 配置反向代理服务器组，Nginx 会根据配置，将请求分发给组里的某一台服务器。tomcats 是服务器组的名称。
- **upstream 模块下的 server 指令：** 配置处理请求的服务器 IP 或域名，端口可选，不配置默认使用 80 端口。通过上面的配置，Nginx 默认将请求依次分配给 100，101，102 来处理，可以通过修改下面这些参数来改变默认的分配策略：
- **weight**
  默认为 1，将请求平均分配给每台 server

```nginx
upstream tomcats {
    server 192.168.0.100:8080 weight=2;  # 2/6次
    server 192.168.0.101:8080 weight=3;  # 3/6次
    server 192.168.0.102:8080 weight=1;  # 1/6次
}
```

> 上例配置，表示 6 次请求中，100 分配 2 次，101 分配 3 次，102 分配 1 次

- **max_fails**
  默认为 1。某台 Server 允许请求失败的次数，超过最大次数后，在 fail_timeout 时间内，新的请求将不会分配给这台机器。如果设置为 0，Nginx 会将这台 Server 置为永久无效状态，然后将请求发给定义了 proxy_next_upstream, fastcgi_next_upstream, uwsgi_next_upstream, scgi_next_upstream, and memcached_next_upstream 指令来处理这次错误的请求。
- **fail_timeout**
  默认为 10 秒。某台 Server 达到 max_fails 次失败请求后，在 fail_timeout 期间内，nginx 会认为这台 Server 暂时不可用，不会将请求分配给它

```nginx
upstream tomcats {
    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;
    server 192.168.0.101:8080 weight=3;
    server 192.168.0.102:8080 weight=1;
}
```

> 192.168.0.100 这台机器，如果有 3 次请求失败，nginx 在 15 秒内，不会将新的请求分配给它。

- **backup**
  备份机，所有服务器挂了之后才会生效

```nginx
upstream tomcats {
    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;
    server 192.168.0.101:8080 weight=3;

    server 192.168.0.102:8080 backup;
}
```

> 在 100 和 101 都挂了之前，102 为不可用状态，不会将请求分配给它。只有当 100 和 101 都挂了，102 才会被启用。

- **down**
  标识某一台 server 不可用。可能能通过某些参数动态的激活它吧，要不真没啥用。

```nginx
upstream tomcats {
    server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15;

    server 192.168.0.101:8080 down;

    server 192.168.0.102:8080 backup;
}
```

> 表示 101 这台 Server 为无效状态，不会将请求分配给它。

- **max_conns**
  限制分配给某台 Server 处理的最大连接数量，超过这个数量，将不会分配新的连接给它。默认为 0，表示不限制。注意：1.5.9 之后的版本才有这个配置

```nginx
upstream tomcats {
    server 192.168.0.100:8080 max_conns=1000;
}
```

> 表示最多给 100 这台 Server 分配 1000 个请求，如果这台 Server 正在处理 1000 个请求，nginx 将不会分配新的请求给到它。假如有一个请求处理完了，还剩下 999 个请求在处理，这时 nginx 也会将新的请求分配给它。

- **resolve**
  将 server 指令配置的域名，指定域名解析服务器。需要在 http 模块下配置 resolver 指令，指定域名解析服务

```nginx
http {
    resolver 10.0.0.1;

    upstream u {
        zone ...;
        ...
        server example.com resolve;
    }
}
```

> 表示 example.com 域名，由 10.0.0.1 服务器来负责解析。

## 二、第三方负载策略

### fair

根据服务器的响应时间来分配请求，响应时间短的优先分配，即负载压力小的优先会分配。
由于 fair 模块是第三方提供的，所以在编译 nginx 源码的时候，需要将 fair 添加到 nginx 模块中。

> 假设我的 nginx 是通过源码安装的，安装在/opt/nginx 目录下，而且安装时没有添加 fair 模块

1. 下载 fair 模块源码

下载地址：https://github.com/csjiabin/nginx-upstream-fair

```bash
cd /opt
wget https://github.com/csjiabin/nginx-upstream-fair/archive/master.zip
unzip master.zip
```

> 解压后的目录名为：nginx-upstream-fair-master

2. 重新编译 nginx，将 fair 模块添加到编译参数

我的 nginx 源码目录在/opt/nginx-1.10.0

```bash
cd /opt/nginx-nginx-1.10.0
./configure --prefix=/opt/nginx --add-module=/opt/nginx-upstream-fair-master
make
```

> 注意：不要执行 `make install`，这样会覆盖之前 nginx 的配置

3. 将新编译的 nginx 可执行程序拷贝到/opt/nginx/sbin/目录下，覆盖之前安装的 nginx

编译后的 nginx 执行程序，放在 nginx 源码的 objs 目录下

```bash
ps -aux | grep nginx
kill -9 nginx进程ID  # 停止nginx服务
cp /opt/nginx-1.10.0/objs/nginx /opt/nginx/sbin/  # 覆盖旧的nginx
nginx # 启动服务
```

配置使用 fair 负载策略模块：

```nginx
upstream tomcats {
    fair;
    server 192.168.0.100:8080;
    server 192.168.0.101:8080;
    server 192.168.0.102:8080;
}
```

> 由于采用 fair 负载策略，配置 weigth 参数改变负载权重将无效。

### url_hash

按请求url的hash结果来分配请求，使每个url定向到同一个后端服务器，服务器做缓存时比较有效。

1.7.2版本以后，url_hash模块已经集成到了nginx源码当中，不需要单独安装。之前的版本仍需要单独安装，下载地址：https://github.com/evanmiller/nginx_upstream_hash 
安装方法和fair模块一样，先下载url_hash源码，然后重新编译nginx源码，将url_hash模块添加到编译配置参数当中，最后将编译后生成的nginx二进制文件替换之前安装的nginx二进制文件即可。

```nginx
upstream tomcats {
    server 192.168.0.100:8080;
    server 192.168.0.101:8080;
    server 192.168.0.102:8080;
    hash $request_uri;
}
```